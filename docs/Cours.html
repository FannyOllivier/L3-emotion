<!DOCTYPE html>
<html lang="en"><head>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/tabby.min.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2e0b4708489a94d7cf3aaa82802539fe.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.9.5">

  <meta name="author" content="Fanny Ollivier">
  <title>CM L1 – Émotion et Cognition</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="site_libs/revealjs/dist/theme/quarto-534cd8e3a96973385dffff3f4709048d.css">
  <link rel="stylesheet" href="slides.css">
  <link href="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Émotion et Cognition</h1>
  <p class="subtitle">Quels rapports entretiennent-elles ? - L3 CM</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Fanny Ollivier 
</div>
<div class="quarto-title-author-email">
<a href="mailto:fanny.ollivier@univ-angers.fr">fanny.ollivier@univ-angers.fr</a>
</div>
</div>
</div>

</section>
<section>
<section id="présentation-du-cours" class="title-slide slide level1 center">
<h1>Présentation du cours</h1>

</section>
<section id="objectifs-du-cours" class="slide level2">
<h2>Objectifs du cours</h2>
<ul>
<li class="fragment">Définir les émotions</li>
<li class="fragment">Comprendre comment les émotions influencent les processus cognitifs (attention/mémoire/raisonnement)</li>
<li class="fragment">Comprendre comment les processus cognitifs peuvent moduler les expériences émotionnelles (régulation émotionnelle)</li>
<li class="fragment">Examiner les différences individuelles dans ces processus et les interactions</li>
</ul>
</section>
<section id="répartition-des-tâches" class="slide level2">
<h2>Répartition des tâches</h2>
<p>Cours :</p>
<p>‒ Apporter des connaissances générales et méthodologiques sur l’étude des relations entre émotion et cognition</p>
<p>Étudiant.e :</p>
<p>‒ Mettre en relation ces connaissances et un champ de recherche à choisir (e.g., vieillissement, apprentissages, développement de l’enfant, orientation)</p>
</section>
<section id="évaluation-du-cours" class="slide level2">
<h2>Évaluation du cours</h2>
<p>‒ Sujet type cadre théorique dans une réponse à un AAP/ abstract (sans les résultats) en un nombre de mots donné</p>
<p><a href="https://jipd-2018.sciencesconf.org/data/pages/Organisation_Horaires_23e_Journees_Internationales_de_Psychologie_Differentielle.pdf">exemple p.31</a></p>
<p>‒ Critères de réussite :</p>
<pre><code>- Sélection et mise en lien de notions apprises en cours 
- Fluidité et lisibilité de la rédaction 
- Apports de sa recherche personnelle sur le sujet (lectures complémentaires)</code></pre>
<aside class="notes">
<p>éviter les catalogues, juxtaposition, récitation de cours</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="source-principale" class="slide level2">
<h2>Source Principale</h2>
<p>‒ Lemaire, P. (2021). <em>Émotion et cognition: Série LMD</em>. De Boeck Supérieur.</p>
<p><img data-src="images/couvLemaire.png"> ## Plan de la première partie du cours</p>
<p><strong>Introduction</strong> =&gt; Quelles questions en psychologie sur le lien entre émotion et cognition ?</p>
<p><strong>Définition des émotions</strong> =&gt; Modèles théoriques</p>
<p><strong>Comment étudier le lien entre émotion et cognition ?</strong> =&gt; Que cherche-t-on ? =&gt; Induire l’émotion ou utiliser ses occurences naturelles =&gt; Induire l’émotion en dehors de la tâche ou par la tâche (incidentes vs.&nbsp;intégrales)</p>
<aside class="notes">
<p>revenir sur cette diapo en début de cours</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="introduction" class="title-slide slide level1 center">
<h1>Introduction</h1>

</section>
<section id="les-émotions-dans-nos-vies" class="slide level2">
<h2>Les émotions dans nos vies</h2>
<p>Rôle central</p>
<ul>
<li class="fragment">Actions</li>
<li class="fragment">Pensées</li>
<li class="fragment">Relations</li>
</ul>
<p>=&gt; guident nos actions au quotidien</p>
<aside class="notes">
<p>«Elles interviennent dans nos actions, nos pensées et nos relations. Elles nous aident à détecter et repérer ce qui est important, à mémoriser, à comprendre et à décider. Elles guident nos actions au quotidien.»</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="les-émotions-dans-la-recherche" class="slide level2">
<h2>Les émotions dans la recherche</h2>
<p>‒ Sciences cognitives et affectives</p>
<p>• Psychologie</p>
<p>• Linguistique</p>
<p>• Philosophie</p>
<p>• Sociologie</p>
<p>• Anthropologie</p>
<p>• Informatique</p>
<p>• Psychiatrie</p>
<p>‒ Depuis les années 80</p>
<aside class="notes">
<p>Parce qu’elles sont centrales, elles sont étudiées par différentes disciplines. Exemples : - Informatique : IA</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="les-émotions-dans-la-recherche-1" class="slide level2">
<h2>Les émotions dans la recherche</h2>
<p>Actes du colloque « Émotions et science : interactions », université de Nice (2020)</p>

<img data-src="images/actesNice.png" class="r-stretch"></section>
<section id="quelles-questions-peuvent-elles-se-poser-dans-la-recherche" class="slide level2">
<h2>Quelles questions peuvent-elles se poser dans la recherche ?</h2>
<p><a href="https://app.wooclap.com/events/YNCKQT/live-session">lien Wooclap</a></p>
<p>ou wooclap.com, code YNCKQT</p>

<img data-src="images/wooclap.png" class="r-stretch"></section>
<section id="exemples-de-questions-actuelles-en-psychologie-des-émotions" class="slide level2 scrollable">
<h2>Exemples de questions actuelles en psychologie des émotions</h2>
<p>‒ Comment sait-on si quelqu’un éprouve une émotion ? Comment sait-on quelle émotion il éprouve ? Qu’est-ce qu’une émotion ?</p>
<p>‒ Combien d’émotions fondamentales de base différentes existe-t-il ? Quelles sont-elles ? Comment faisons-nous pour distinguer entre plusieurs émotions ?</p>
<p>‒ Qu’est-ce qu’une émotion forte (ou intense) vs.&nbsp;une émotion moins forte ?</p>
<p>‒ Les émotions sont-elles universelles et innées (et présentes dans toutes les cultures) ou varient-elles selon la culture ? Idem pour l’expression des émotions ?</p>
<p>‒ Les femmes sont-elles plus émotionnelles que les hommes ? Les personnes jeunes ont-elles plus d’émotions, des émotions plus intenses que les âgés? Les émotions évoluent-elles au cours de la vie ? Certains individus sont-ils plus émotionnels que d’autres ? Comment le savoir ?</p>
<p>‒ Les animaux ont-ils des émotions ?</p>
<p>‒ Nos émotions sont-elles différentes lorsque nous sommes seuls à vivre un événement émotionnel et lorsque nous sommes avec un autre ou avec d’autres ?</p>
<p>‒ Comment formulons-nous nos jugements (discrimination, détermination, identification) émotionnels ?</p>
<p>‒ A quoi servent les émotions ? Pourrions-nous vivre sans émotion?</p>
<p>‒ Comment les émotionsinfluencent-elles nos performances cognitives?</p>
<aside class="notes">
<p>Voici quelques grandes questions posées par la psychologie des émotions. Grâce à toutes ces questions, on comprend mieux ce que sont nos émotions, quand nous éprouvons des émotions et ce qui les déclenche, pourquoi nous avons des émotions, et l’impact des émotions sur la cognition.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="temps-de-réflexion-personnel-et-questions" class="slide level2">
<h2>Temps de réflexion personnel et questions</h2>
<p>Dans quel champ aimeriez-vous réfléchir à la question du lien entre émotion et cognition ?</p>
<p>Quels sont vos questionnements de chercheurs a priori ?</p>
<aside class="notes">
<p>prendre le temps d’y réfléchir, de se poser des questions, qui serviront de base à la réflexion</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<p>Si vous avez envie de partager vos questions : <a href="https://app.wooclap.com/events/YNCKQT/live-session">lien Wooclap</a></p>
</section></section>
<section id="émotions-définition-et-méthodologie-expérimentale" class="title-slide slide level1 center">
<h1>Émotions : définition et méthodologie expérimentale</h1>
<p>À comprendre dans cette partie de cours :</p>
<p>‒ Ce qu’est une émotion</p>
<p>‒ Comment étudier les émotions</p>
<p>‒ Comment, du point de vue méthodologique, étudier l’impact des émotions sur la cognition</p>
</section>

<section>
<section id="définition-des-émotions" class="title-slide slide level1 center">
<h1>Définition des émotions</h1>

</section>
<section id="quest-ce-quune-émotion" class="slide level2">
<h2>Qu’est-ce qu’une émotion ?</h2>
<p><em>Chacun sait ce qu’est une émotion jusqu’à ce qu’on lui demande d’en donner une définition.</em> <em>À ce moment-là, il semble que plus personne ne le sache.</em></p>
<p>Fehr &amp; Russell (1984)</p>
<aside class="notes">
<p>Années 80, grand essor des questions scientifiques sur les émotions</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="émotions-définitions" class="slide level2 scrollable">
<h2>Émotions : définitions</h2>
<p>Multiples définitions mais points communs</p>
<p>‒ États internes observables ou non (comportements, expressions verbales ou faciales)</p>
<p>‒ S’accompagnent de réactions physiologiques (changement de fréquence cardiaque, transpiration, contraction des muscles …)</p>
<p>‒ Réponses psychologiques et/ou physiologiques d’intensité, de durée, de complexité variables à une situation</p>
<p>‒ Plusieurs types d’émotions</p>
</section>
<section id="émotions-définition" class="slide level2">
<h2>Émotions : définition</h2>
<p>«Patrons biologiquement fondés de perception, d’expérience, de physiologie, d’action et de communication, caractérisés par leur aspect épisodique, de courte durée, et qui se produisent en réponse à des défis et opportunités physiques et sociaux spécifiques.»</p>
<pre><code>(Keltner &amp; Gross, 1999, p.468)</code></pre>
</section>
<section id="quest-ce-quune-émotion-1" class="slide level2">
<h2>Qu’est-ce qu’une émotion ?</h2>
<p>‒ Un ensemble de réponses, d’intensité, de durée et de complexité variables qui s’expriment de manière plus ou moins publique/privée</p>
<p>‒ Différent de l’humeur ou des sentiments</p>
<p>‒ Terme chapeau « affects » :</p>
<pre><code>- Émotions (e.g., colère, tristesse)
- Réponse au stress
- Humeur (dépression, euphorie) </code></pre>
<aside class="notes">
<p>Humeur : durable Sentiment : durée longue, construction consciente, vient d’une évaluation subjective (pas en réaction comme l’émotion) Stress: pas sentiment, ni émotion, mais réaction physiologique et psychique à l’environnement. Concepts distingués mais liés (différences physiologiques dans le traitement)</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="différences-entre-émotion-et-autres-affects" class="slide level2">
<h2>Différences entre émotion et autres affects</h2>

<img data-src="images/comparatif.png" class="r-stretch"><aside class="notes">
<p>Synchronisation : l’émotion est synchronisée avec un événement (ou le fait d’y penser) Appraisal : évaluation cognitive</p>
<p>FIN S1</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="caractéristiques-dune-émotion" class="slide level2 scrollable">
<h2>Caractéristiques d’une émotion</h2>
<p>Quand l’émotion survient-elle ?</p>
<ul>
<li class="fragment"><p>Nos émotions dépendent de la situation (évaluation cognitive), mais pas uniquement</p></li>
<li class="fragment"><p>Elles dépendent aussi de notre interprétation de la situation =&gt; <strong>Théorie de la ré-évaluation cognitive</strong> (Laarus, 1991; Scherer, Schorr &amp; Johnstone, 2001)</p></li>
<li class="fragment"><p>notre évaluation mentale de la situation :</p>
<ul>
<li class="fragment">sens de la situation pour nous (ce qu’elle signifie)</li>
<li class="fragment">aide ou menace pour nos objectifs</li>
<li class="fragment">est-ce qu’on se sent capable d’y faire face ?</li>
</ul>
<p>provoque les émotions</p></li>
<li class="fragment"><p>La ré-évaluation cognitive permet de changer volontairement son interprétation de la situation pour modifier l’émotion ressentie</p></li>
</ul>
<aside class="notes">
<p>Appraisal theory</p>
<p>Exemples - Un étudiant reçoit une mauvaise note.</p>
<p>Évaluation initiale : « Je suis nul, je vais échouer » → tristesse, découragement.</p>
<p>Ré-évaluation : « C’est un indicateur de ce que je dois travailler » → motivation, espoir.</p>
<ul>
<li>Une personne parle en public et voit quelqu’un froncer les sourcils.</li>
</ul>
<p>Évaluation initiale : « Il me juge négativement » → anxiété.</p>
<p>Ré-évaluation : « Il est peut-être juste concentré ou fatigué » → diminution du stress</p>
<p>Ré-évaluation cognitive : mécanisme de régulation émotionnelle, on en reparlera quand on traitera ce point</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="caractéristiques-dune-émotion-1" class="slide level2">
<h2>Caractéristiques d’une émotion</h2>
<p>Nature multi-dimensionnelle</p>
<ul>
<li class="fragment">Émotion : multitude de réactions, plus ou moins synchronisées ; réactions physiologiques, subjectives (vécu, ressenti), comportementales et sociales</li>
</ul>
</section>
<section id="le-modèle-modal-de-lémotion" class="slide level2">
<h2>Le modèle modal de l’émotion</h2>
<p><img data-src="images/modelemodal.png"> <em>Barrett et al., 2007; Gross, 1998</em></p>
<aside class="notes">
<p>Une émotion survient lorsque nous nous trouvons dans une situation ou face à un stimulus, après évaluation (du caractère dangereux ou pas, ou du caractère agréable/désagréable). On porte plus ou moins attention à certains aspects de la situation. On donne un sens à ce que l’on perçoit (évaluation). Puis réponse émotionnelle. L’émotion peut s’exprimer à différents niveaux (depuis les niveaux physiologiques comme l’accélération du rythme cardiaque) jusqu’aux niveaux psychologiques et comportementaux (comme un ressenti de peur et une fuite).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="le-modèle-modal-de-lémotion-1" class="slide level2">
<h2>Le modèle modal de l’émotion</h2>
<ul>
<li class="fragment"><p>Processus dynamique en plusieurs étapes (!= d’un réflexe automatique)</p></li>
<li class="fragment"><p>montre où et comment peut intervenir la régulation émotionnelle</p>
<ul>
<li class="fragment">changer la situation</li>
<li class="fragment">changer l’attention que l’on y prête</li>
<li class="fragment">réévaluer la situation</li>
<li class="fragment">après le déclenchement de l’émotion : contrôler la respiration, l’expression</li>
</ul></li>
</ul>
<aside class="notes">
<p>ex Une personne doit passer un entretien d’embauche/master.</p>
<p>Situation : entretien imminent.</p>
<p>Attention : elle se concentre sur ses erreurs passées.</p>
<p>Évaluation : « Je vais rater. »</p>
<p>Réponse : anxiété, mains moites.</p>
<p>Régulation possible :</p>
<p>Avant : se focaliser sur ses réussites (attention).</p>
<p>Pendant : reformuler mentalement (« c’est une opportunité »).</p>
<p>Après : respiration lente pour réduire la tension.</p>
<p>ou ex d’un conducteur qui se fait couper la route</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="taxonomie-des-émotions" class="slide level2">
<h2>Taxonomie des émotions</h2>
<p>‒ Toujours en questionnement dans la littérature (Eckman, 1984; Averill, 1980; Scherer, 1984), voir Gross &amp; Barrett (2011)</p>
<p>‒ Émotions de base</p>
<pre><code>- joie, surprise, 
- colère, tristesse, dégoût, peur</code></pre>
<p>‒ Émotions réflexives</p>
<pre><code>- jalousie, envie (émotions comparatives)
- honte, culpabilité, embarras, fierté, orgueil (émotions d'auto-évaluation)</code></pre>
<aside class="notes">
<p>Comment classer les émotions ? Ex de questionnement. Basic 6 en questionnement (parfois 7 quand on ajoute le mépris). Ex : Keltner et al.&nbsp;2021 proposent une taxonomie avec davantage d’émotions positives. Émotions de base universelles ou non ? Questionne l’existence d’une «base» à proprement parler Eckman (1984) : uniquement des émotions de base et elles sont universelles. Perspective universaliste Averill (1980) : culturel et nécessité d’étudier d’autres émotions (ex: culpabilité). Pas de correspondance parfaite entre les cultures. Le fait qu’une émotion est fondamentale dépend de la culture :ex du «liget» chez les Ilongots (chasseurs de tête des Philippines (caractère agressif exaltant et grisant lorsqu’une tête d’une autre ethnie est tranchée). Ou le hygge en danois Scherer (1984) : approche intégrée. Ce n’est pas parce que des mots différents sont utilisés qu’il ne s’agit pas des mêmes émotions, mais on observe tout de même des différences culturelles.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="deux-dimensions-pour-caractériser-les-émotions" class="slide level2">
<h2>Deux dimensions pour caractériser les émotions</h2>
<p>‒ La valence : de négative à positive</p>
<p>‒ L’intensité : de faible à forte</p>
<p><img data-src="images/valenceInt.png"> Valence</p>
<aside class="notes">
<p>valence : continuum plaisant/déplaisant</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="exercice-valence-et-intensité-émotionnelles" class="slide level2">
<h2>Exercice : Valence et intensité émotionnelles</h2>
<p>5 questions</p>
<p><a href="https://app.wooclap.com/events/YNCKQT/live-session">lien Wooclap</a></p>
</section>
<section id="émotions-de-base-quels-déclencheurs-quels-signes" class="slide level2">
<h2>Émotions de base : quels déclencheurs ? Quels signes ?</h2>
<p>‒ Différences inter-individuelles mais les expressions psychologiques, comportementales et physiologiques des émotions présentent un profil général dans le développement typique</p>
<aside class="notes">
<p>Profil général mais différences. Par ex : - TSA : réactions physiologiques (électrodermales/ pupillaires) préservées ou amoindries selon les études, cardiaques similaires ((2) Lydon, S. et al.&nbsp;(2016) Dev. Neurorehabilitation 19, 335–355 ; (3) Aguillon-Hernandez, N. et al.&nbsp;(2020) J. Child Psychol. Psychiatry 61, 768–778). Expressions comportementales des émotions différentes : Briot, K., Pizano, A., Bouvard, M., &amp; Amestoy, A. (2021). New technologies as promising tools for assessing facial emotion expressions impairments in ASD: A systematic review. Frontiers in Psychiatry, 12, 634756. Faire une heure sur émotion et cognition dans le développement atypique ?</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="déclencheurs" class="slide level2 scrollable">
<h2>Déclencheurs</h2>
<ul>
<li class="fragment"><p>Colère</p>
<ul>
<li class="fragment">Face à un obstacle</li>
<li class="fragment">Quand un besoin n’est pas satisfait</li>
</ul></li>
<li class="fragment"><p>Tristesse</p>
<ul>
<li class="fragment">Situation de manque, d’absence</li>
<li class="fragment">Quand nous n’obtenons pas ce que nous voulons, obtenons ce que nous ne voulons pas</li>
</ul></li>
<li class="fragment"><p>Joie</p>
<ul>
<li class="fragment">Réussite</li>
<li class="fragment">Satisfaction d’un ou plusieurs de nos besoins (précis)</li>
</ul></li>
</ul>
</section>
<section id="expressions-faciales" class="slide level2 scrollable">
<h2>Expressions faciales</h2>

<img data-src="images/expressions.png" class="r-stretch"></section>
<section id="changements-physiologiques-levenson-et-al.-1990" class="slide level2 scrollable">
<h2>Changements physiologiques (Levenson et al., 1990)</h2>

<img data-src="images/physioLevenson.png" class="r-stretch"><aside class="notes">
<p>fin S2</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="recherche-que-cherche-t-on-à-élucider" class="slide level2">
<h2>Recherche : que cherche-t-on à élucider ?</h2>
<p>Questions déclinables pour chaque fonction cognitive</p>
<ul>
<li class="fragment">Les émotions affectent-elles nos performances ?</li>
<li class="fragment">Si oui, dans quelles conditions ?</li>
<li class="fragment">Dans quel sens et dans quelles proportions ?</li>
<li class="fragment">Par quels mécanismes ?</li>
</ul>
</section></section>
<section>
<section id="comment-étudier-le-lien-entre-émotions-et-cognition" class="title-slide slide level1 center">
<h1>Comment étudier le lien entre émotions et cognition ?</h1>

</section>
<section id="principes-méthodologiques-généraux-de-létude-du-lien-émotioncognition" class="slide level2 scrollable">
<h2>Principes méthodologiques généraux de l’étude du lien émotion/cognition</h2>
<ul>
<li class="fragment"><p>Réalisation d’une tâche cognitive connue</p>
<ul>
<li class="fragment">Ex : tâche de raisonnement, de rappel</li>
</ul></li>
<li class="fragment"><p>Dans une condition :</p>
<ul>
<li class="fragment">Émotionnelle/neutre</li>
<li class="fragment">En inter ou en intra (si possible)</li>
</ul></li>
<li class="fragment"><p>Comparaison des performances en fonction de l’état émotionnel du participant</p>
<ul>
<li class="fragment">Déterminer si les mécanismes connus pour la tâche cognitive sont mis en œuvre différemment en condition émotionnelle et en condition neutre</li>
</ul></li>
</ul>
<aside class="notes">
<p>Mécanismes connus par les chercheurs pour pouvoir comprendre le changement potentiellement observé lorsqu’on introduit l’émotion</p>
<p>Exemple d’étude : est-ce que les émotions influencent une tâche de recherche visuelle Fox et al.&nbsp;(2007)</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="exemple---émotion-et-recherche-visuelle" class="slide level2 scrollable">
<h2>Exemple - Émotion et recherche visuelle</h2>
<p>Fox et al.&nbsp;(2007)</p>
<ul>
<li class="fragment"><p>Photos du IAPS : pistolets, serpents, fleurs et champignons</p>
<p><em>images réelles dans l’expérimentation, les figures du diapo sont des illustrations</em></p></li>
<li class="fragment"><p>Consigne : Trouver si toutes les images sont les mêmes ou non dans chaque set</p></li>
</ul>
<p><img data-src="images/imagesfox.png"> Que mesure-t-on ? Pourquoi ? <a href="https://app.wooclap.com/events/YNCKQT/live-session">lien Wooclap</a></p>
<aside class="notes">
<p>International Affective Picture System/ image proposée pour mieux comprendre mais la vraie expé s’est faite à partir de photos et non de dessins, ce qui change au niveau méthodo. Images IAPS non disponibles car choix de garder la primeur des images pour les expés des créateurs. Autres bases (OASIS par ex) sont ouvertes. 50% des sets contiennent les mêmes images, 50% des sets contiennent un intrus Pas de différence significative sur les erreurs, mais différences sur les temps de réaction</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="exemple---émotion-et-recherche-visuelle-fox-et-al.-2007" class="slide level2">
<h2>Exemple - Émotion et recherche visuelle (Fox et al., 2007)</h2>
<p>Résultats</p>

<img data-src="images/resultfox.png" class="r-stretch"><aside class="notes">
<p>International Affective Picture System/ image proposée pour mieux comprendre mais la vraie expé s’est faite à partir de photos et non de dessins, ce qui change au niveau méthodo. Images IAPS non disponibles car choix de garder la primeur des images pour les expés des créateurs. Autres bases (OASIS par ex) sont ouvertes. 50% des sets contiennent les mêmes images, 50% des sets contiennent un intrus Pas de différence significative sur les erreurs, mais différences sur les temps de réaction</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="méthodologies-pour-létude-des-émotions" class="slide level2">
<h2>Méthodologies pour l’étude des émotions</h2>
<p>Manipulations expérimentales =&gt; induction</p>
<p>Occurrences naturelles</p>
</section>
<section id="manipulations-expérimentales-induction" class="slide level2">
<h2>Manipulations expérimentales (induction)</h2>
<ul>
<li class="fragment">Stimuli émotionnels (images ou mots à valence émotionnelle; revue Kenealy, 1986 pour des mots; images IAPS, Lang, Bradley, &amp; Cuthbert, 2005 ; NAPS ; OASIS)</li>
</ul>
<aside class="notes">
<p>Remarque : une critique adressée à la banque d’image IAPS c’est qu’elle a été utilisée et testée quasi uniquement dans le minority world (aussi appelé WEIRD pour White Educated Industrialized Rich Democratic) D’autres bases (en open access) ont été créées depuis : https://imotions.com/blog/learning/research-fundamentals/iaps-international-affective-picture-system/ Nencki Affective Picture System (NAPS)This database “consists of 1,356 realistic, high-quality photographs that are divided into five categories (people, faces, animals, objects, and landscapes)” and has been rated for both valence and arousal, as IAPS was, but with a measurement of “approach-avoidance” rather than dominance / control. The database also provides measurements of physical properties of the photographs – the luminance, contrast, and entropy, which can be important when these need to be controlled for (such as with pupillometry).Subsets of the database have also been formed to provide data that has been more intensively categorized, such as for&nbsp;discrete emotional categories,&nbsp;erotic content, and&nbsp;fear inducing&nbsp;material. Open Affective Standardized Image Set (OASIS)OASIS is an “open-access online stimulus set containing 900 color images depicting a broad spectrum of themes, including humans, animals, objects, and scenes, along with normative ratings on two affective dimensions – valence… and arousal”. The database is also “not subject to the copyright restrictions that apply to the International Affective Picture System” which opens up the possibilities for use. Geneva affective picture database (GAPED)GAPED is a database consisting of 730 photos, “rated according to valence, arousal, and the congruence of the represented scene with internal (moral) and external (legal) norms”. The negatively-valenced photos include “spiders, snakes, and scenes that induce emotions related to the violation of moral and legal norms”, while the positively-valenced photos include “mainly human and animal babies as well as nature sceneries”. Neutral pictures primarily show inanimate objects. Emotional Picture Set (EmoPicS)As research into emotions often requires a large number of stimulus presentations, EmoPicS has been built to add to the material available. The database “comprises a total of 378 standardized color photographs with different semantic content (diverse social situations, animals and plants) as well as different emotional intensity and valence”. The database is only available for academic research or clinical work. EmoMadridEmoMadrid is a database of over 800 photos with different affectiva content. The data includes information about the “affective valence, arousal, spatial frequency, luminosity and physical complexity”. Military Affective Picture System (MAPS)MAPS is an image database that “provides pictures normed for both civilian and military populations to be used in research on the processing of emotionally-relevant scenes common among military populations”. It consists of “240 images depicting scenes common among military populations”. The data was scored in the same way as IAPS, with measures of valence, arousal, and dominance. Development and Validation of the Image Stimuli for Emotion Elicitation (ISEE)The ISEE was built as a “set of reliable pictorial stimuli, which elicited target emotions stably over time”. The ISEE, in comparison to IAPS, GAPED, and others, has been tested for stability in emotional elicitation over repeated presentations. The database consists of 356 photos, selected from an initial pool of over 10,000. Open Library of Affective Foods (OLAF)OLAF as a database of images “has the specific purpose of studying emotions toward food” and “depicts high-calorie sweet and savory foods and low-calorie fruits and vegetables, portraying foods within natural scenes matching the IAPS features”. The images are available to be downloaded directly from the website. DIsgust-RelaTed-Images (DIRTI)Built specifically for eliciting feelings of disgust, the DIRTI database “consists of 240 disgust-inducing pictures divided into six categories (food, animals, body products, injuries/infections, death, and hygiene)” as well as 60 neutral pictures. The photos were rated on scales measuring disgust, fear, valence, and arousal and can be downloaded directly through the link above</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="manipulations-expérimentales-induction---bases-dimages" class="slide level2">
<h2>Manipulations expérimentales (induction) - bases d’images</h2>
<p>Exemple : OASIS</p>
<p><a href="https://www.benedekkurdi.com/%23oasis">lien OASIS</a></p>
<ul>
<li class="fragment">900 images</li>
<li class="fragment">échelle en deux dimensions : valence/ intensité</li>
</ul>
</section>
<section id="manipulations-expérimentales-induction---oasis" class="slide level2 scrollable">
<h2>Manipulations expérimentales (induction) - OASIS</h2>
<ul>
<li class="fragment"><p>Kurdi, B., Lozano, S., &amp; Banaji, M. R. (2017). Introducing the Open Affective Standardized Image Set (OASIS). Behavior Research Methods, 49(2), 457–470. https://doi.org/10.3758/s13428-016-0715-3</p></li>
<li class="fragment"><p>Pas d’effet de genre (une fois enlevées les images -18 explicites)</p></li>
<li class="fragment"><p>Effets négligeables de</p>
<ul>
<li class="fragment">l’âge,</li>
<li class="fragment">des revenus,</li>
<li class="fragment">l’orientation politique (sauf -18 et violence)</li>
</ul></li>
</ul>
<aside class="notes">
<p>Corrélations entre valence homme/femme et intensité homme/femme très fortes. Si on regarde le tableau des valences et intensité moyennes, on voit des différences entre hommes et femmes, mais la corrélation est très forte (à plus de .92). Fin S2 ?</p>
<p>https://www.benedekkurdi.com/#!portfolio/project-4.html https://db.tt/yYTZYCga /</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="site_libs/revealjs/plugin/multiplex/socket.io.js"></script>
  <script src="site_libs/revealjs/plugin/multiplex/multiplex.js"></script>
  <script src="site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="site_libs/revealjs/plugin/search/search.js"></script>
  <script src="site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'multiplex': {"secret":null,"id":"2f128b22c9651d7a025b12d738f6b1ad7af0ee2fbde39ea9247460e36a762ce7","url":"https://multiplex.up.railway.app/"},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/fannyollivier\.github\.io\/L3-emotion");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>